0: GPU available: True (cuda), used: True
0: TPU available: False, using: 0 TPU cores
0: IPU available: False, using: 0 IPUs
0: HPU available: False, using: 0 HPUs
0: /scratch/mch/sadamov/miniforge3/envs/ddp_starter/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default
0: Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
1: Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
3: Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
2: Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
0: ----------------------------------------------------------------------------------------------------
0: distributed_backend=nccl
0: All distributed processes registered. Starting with 4 processes
0: ----------------------------------------------------------------------------------------------------
0: 
2: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
0: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
3: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
1: LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
0: 
0:   | Name   | Type   | Params
0: ----------------------------------
0: 0 | linear | Linear | 15    
0: ----------------------------------
0: 15        Trainable params
0: 0         Non-trainable params
0: 15        Total params
0: 0.000     Total estimated model params size (MB)
0: SLURM auto-requeueing enabled. Setting signal handlers.
1: SLURM auto-requeueing enabled. Setting signal handlers.
2: SLURM auto-requeueing enabled. Setting signal handlers.
3: SLURM auto-requeueing enabled. Setting signal handlers.
0: `Trainer.fit` stopped: `max_epochs=10` reached.
